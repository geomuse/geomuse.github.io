<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-01-25T23:40:05+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">g</title><subtitle>keep it simple</subtitle><entry><title type="html">金钱心理学</title><link href="http://localhost:4000/review/learning/review118/" rel="alternate" type="text/html" title="金钱心理学" /><published>2025-01-25T13:01:30+08:00</published><updated>2025-01-25T13:01:30+08:00</updated><id>http://localhost:4000/review/learning/review118</id><content type="html" xml:base="http://localhost:4000/review/learning/review118/"><![CDATA[<p>你可以选择一份虽然工资低但对你而言更有价值的工作,存钱的价值</p>

<p>选择与时间是一个通用的货币
<br />
<br /></p>

<p>在你负担得起的范围内舒适地生活，不产生过多欲望，</p>

<p>你会避免现代西方世界中许多人要承受的巨大社会压力</p>

<p><br />
获得一定程度的生活自主性并不需要你拿到医生那么高的薪水。</p>

<p>最主要的秘诀是控制你的欲望，在能力范围内尽可能节俭地生活。</p>

<p>长期的投资手法–低成本的指数基金。</p>]]></content><author><name></name></author><category term="review" /><category term="learning" /><summary type="html"><![CDATA[你可以选择一份虽然工资低但对你而言更有价值的工作,存钱的价值]]></summary></entry><entry><title type="html">有点忧郁倾向的自己(2)</title><link href="http://localhost:4000/review/diary/diary007/" rel="alternate" type="text/html" title="有点忧郁倾向的自己(2)" /><published>2025-01-24T13:01:30+08:00</published><updated>2025-01-24T13:01:30+08:00</updated><id>http://localhost:4000/review/diary/diary007</id><content type="html" xml:base="http://localhost:4000/review/diary/diary007/"><![CDATA[<p>每天记录自己的生活一点点滴滴，无论负面或者正面也好</p>

<table>
  <thead>
    <tr>
      <th>正面</th>
      <th>负面</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>爱我的家人</td>
      <td>坚持不了自己的兴趣</td>
    </tr>
    <tr>
      <td>富足的财富</td>
      <td>没有有价值的未来</td>
    </tr>
    <tr>
      <td>健康的财务</td>
      <td>有一身病的躯壳</td>
    </tr>
  </tbody>
</table>]]></content><author><name></name></author><category term="review" /><category term="diary" /><summary type="html"><![CDATA[每天记录自己的生活一点点滴滴，无论负面或者正面也好]]></summary></entry><entry><title type="html">有点忧郁倾向的自己(1)</title><link href="http://localhost:4000/review/diary/diary006/" rel="alternate" type="text/html" title="有点忧郁倾向的自己(1)" /><published>2025-01-23T13:01:30+08:00</published><updated>2025-01-23T13:01:30+08:00</updated><id>http://localhost:4000/review/diary/diary006</id><content type="html" xml:base="http://localhost:4000/review/diary/diary006/"><![CDATA[<p>忧郁倾向，会思考负面的回忆一一直直循环。</p>]]></content><author><name></name></author><category term="review" /><category term="diary" /><summary type="html"><![CDATA[忧郁倾向，会思考负面的回忆一一直直循环。]]></summary></entry><entry><title type="html">把力氣花在你想要的生活上</title><link href="http://localhost:4000/review/life/review117/" rel="alternate" type="text/html" title="把力氣花在你想要的生活上" /><published>2025-01-22T13:01:30+08:00</published><updated>2025-01-22T13:01:30+08:00</updated><id>http://localhost:4000/review/life/review117</id><content type="html" xml:base="http://localhost:4000/review/life/review117/"><![CDATA[<p>物慾不是壞事，控制不了的物慾才是壞事。</p>

<p>每個人都有自己享樂的權利，只要自己開心自己覺得值，別人的質疑都通通與我無關
活得比我好的我只有羨慕，比我差的我也不會指指點點，反正死的時候一切清零。</p>

<p>记得购买医疗保险和紧急备用金</p>

<p>一輩子還長著，沒什麼花掉的錢是賺不回來的。</p>

<p>成为一个有趣的灵魂</p>]]></content><author><name></name></author><category term="review" /><category term="life" /><summary type="html"><![CDATA[物慾不是壞事，控制不了的物慾才是壞事。]]></summary></entry><entry><title type="html">程式做单元测试的重要性</title><link href="http://localhost:4000/review/diary/diary005/" rel="alternate" type="text/html" title="程式做单元测试的重要性" /><published>2025-01-21T13:01:30+08:00</published><updated>2025-01-21T13:01:30+08:00</updated><id>http://localhost:4000/review/diary/diary005</id><content type="html" xml:base="http://localhost:4000/review/diary/diary005/"><![CDATA[<p>当程式变得复杂后，可能需要编写一些测试，并不是孤立检查各个模块，而是要验证模块之间是否能正确地互动。</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">unittest</span>

<span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span>

<span class="k">def</span> <span class="nf">minus</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">-</span><span class="n">b</span>

<span class="k">def</span> <span class="nf">times</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span><span class="o">*</span><span class="n">b</span> 

<span class="k">def</span> <span class="nf">divided</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">b</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">a</span><span class="o">/</span><span class="n">b</span>
    <span class="k">else</span> <span class="p">:</span>
        <span class="k">return</span> <span class="bp">None</span>
    
<span class="k">class</span> <span class="nc">test_math_operation</span><span class="p">(</span><span class="n">unittest</span><span class="p">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">test_add</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="nf">add</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="nf">add</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="nf">add</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span><span class="mi">11</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_minus</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="nf">minus</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="nf">minus</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="nf">minus</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="mi">9</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">test_times</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="nf">times</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">test_divied</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="nf">divided</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="nf">divided</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">assertEqual</span><span class="p">(</span><span class="nf">divided</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="mi">10</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>

    <span class="n">unittest</span><span class="p">.</span><span class="nf">main</span><span class="p">()</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="review" /><category term="diary" /><summary type="html"><![CDATA[当程式变得复杂后，可能需要编写一些测试，并不是孤立检查各个模块，而是要验证模块之间是否能正确地互动。]]></summary></entry><entry><title type="html">关于LSTM的模型建构(2)</title><link href="http://localhost:4000/review/diary/diary004/" rel="alternate" type="text/html" title="关于LSTM的模型建构(2)" /><published>2025-01-20T13:01:30+08:00</published><updated>2025-01-20T13:01:30+08:00</updated><id>http://localhost:4000/review/diary/diary004</id><content type="html" xml:base="http://localhost:4000/review/diary/diary004/"><![CDATA[<p>LSTM 是一种广泛用于时间序列预测和序列数据建模的深度学习模型。</p>

<hr />

<h3 id="1-怎么建模"><strong>1. 怎么建模？</strong></h3>
<h4 id="步骤"><strong>步骤：</strong></h4>
<ol>
  <li><strong>准备数据：</strong>
    <ul>
      <li>确保数据按时间序列排序。</li>
      <li>标准化或归一化数据，使其在相似的数值范围内。</li>
      <li>划分训练集、验证集和测试集。</li>
    </ul>
  </li>
  <li><strong>定义 LSTM 模型架构：</strong>
使用 Python 的 <code class="language-plaintext highlighter-rouge">Keras</code> 或 <code class="language-plaintext highlighter-rouge">PyTorch</code> 构建 LSTM：
    <ul>
      <li><strong>输入层：</strong> 定义时间步长和特征数量。</li>
      <li><strong>LSTM 层：</strong> 定义 LSTM 单元的数量（即隐层维度）。</li>
      <li><strong>全连接层：</strong> 用于生成预测结果。</li>
      <li><strong>输出层：</strong> 输出时间序列预测值或分类结果。</li>
    </ul>

    <p><strong>Keras 示例：</strong></p>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Dense</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">LSTM</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">time_steps</span><span class="p">,</span> <span class="n">features</span><span class="p">)))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># 输出单值预测
</span><span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="sh">'</span><span class="s">adam</span><span class="sh">'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">mse</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div>    </div>

    <p><strong>PyTorch 示例：</strong></p>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">LSTMModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">LSTMModel</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
       
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>  <span class="c1"># 获取最后一个时间步
</span>        <span class="k">return</span> <span class="n">out</span>
</code></pre></div>    </div>
  </li>
  <li><strong>训练模型：</strong>
    <ul>
      <li>使用梯度下降算法（如 Adam 或 RMSprop）。</li>
      <li>定义损失函数（MSE、MAE 等）。</li>
      <li>设置早停机制，避免过拟合。</li>
    </ul>
  </li>
  <li><strong>测试和验证：</strong>
    <ul>
      <li>用验证集评估模型性能。</li>
      <li>调整模型架构和参数。</li>
    </ul>
  </li>
</ol>

<hr />

<h3 id="2-怎么调整"><strong>2. 怎么调整？</strong></h3>
<h4 id="模型调整"><strong>模型调整：</strong></h4>
<ul>
  <li><strong>时间步长 (Time Steps):</strong>
增减输入的时间步长，影响模型捕获历史信息的能力。</li>
  <li><strong>隐藏单元数 (Hidden Units):</strong>
增加 LSTM 层的神经元数量，提高模型的表达能力。</li>
  <li><strong>LSTM 层数 (Stacked LSTMs):</strong>
增加 LSTM 层数以提高非线性建模能力。</li>
</ul>

<h4 id="正则化手段"><strong>正则化手段：</strong></h4>
<ul>
  <li>添加 Dropout：
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Dropout</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>  <span class="c1"># 20%丢弃率
</span></code></pre></div>    </div>
  </li>
  <li>使用权重正则化防止过拟合。</li>
</ul>

<hr />

<h3 id="3-怎么调参"><strong>3. 怎么调参？</strong></h3>
<h4 id="常见超参数"><strong>常见超参数：</strong></h4>
<ol>
  <li><strong>学习率 (Learning Rate)：</strong>
    <ul>
      <li>调整学习率大小，常用范围：<code class="language-plaintext highlighter-rouge">0.001</code> 到 <code class="language-plaintext highlighter-rouge">0.0001</code>。</li>
    </ul>
  </li>
  <li><strong>Batch Size：</strong>
    <ul>
      <li>通常选择 <code class="language-plaintext highlighter-rouge">32</code>, <code class="language-plaintext highlighter-rouge">64</code>, <code class="language-plaintext highlighter-rouge">128</code>。</li>
    </ul>
  </li>
  <li><strong>时间步长 (Sequence Length)：</strong>
    <ul>
      <li>选择 <code class="language-plaintext highlighter-rouge">10-100</code> 的时间步，视具体问题而定。</li>
    </ul>
  </li>
  <li><strong>隐藏单元数 (Hidden Units)：</strong>
    <ul>
      <li>通常范围为 <code class="language-plaintext highlighter-rouge">32</code> 到 <code class="language-plaintext highlighter-rouge">512</code>。</li>
    </ul>
  </li>
</ol>

<h4 id="调参工具"><strong>调参工具：</strong></h4>
<ul>
  <li><strong>手动调整：</strong> 修改模型代码中的超参数。</li>
  <li><strong>自动调参：</strong> 使用 <code class="language-plaintext highlighter-rouge">Optuna</code> 或 <code class="language-plaintext highlighter-rouge">GridSearchCV</code> 等工具。</li>
  <li><strong>Optuna 示例：</strong>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">optuna</span>

<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">hidden_size</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">hidden_size</span><span class="sh">'</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_float</span><span class="p">(</span><span class="sh">'</span><span class="s">lr</span><span class="sh">'</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nc">LSTMModel</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># 训练代码省略...
</span>    <span class="k">return</span> <span class="n">validation_loss</span>

<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="p">.</span><span class="nf">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="sh">'</span><span class="s">minimize</span><span class="sh">'</span><span class="p">)</span>
<span class="n">study</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
</ul>

<hr />

<h3 id="4-怎么即时输出参数"><strong>4. 怎么即时输出参数？</strong></h3>
<h4 id="方法"><strong>方法：</strong></h4>
<ol>
  <li><strong>通过回调函数实时监控：</strong>
    <ul>
      <li>使用 Keras 的 <code class="language-plaintext highlighter-rouge">Callback</code> 机制：
        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">keras.callbacks</span> <span class="kn">import</span> <span class="n">LambdaCallback</span>

<span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">: Loss=</span><span class="si">{</span><span class="n">logs</span><span class="p">[</span><span class="sh">'</span><span class="s">loss</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">, Val_Loss=</span><span class="si">{</span><span class="n">logs</span><span class="p">[</span><span class="sh">'</span><span class="s">val_loss</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="n">callback</span> <span class="o">=</span> <span class="nc">LambdaCallback</span><span class="p">(</span><span class="n">on_epoch_end</span><span class="o">=</span><span class="n">on_epoch_end</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callback</span><span class="p">])</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>保存参数：</strong>
    <ul>
      <li>保存模型权重：
        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="sh">'</span><span class="s">model_weights.h5</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div>        </div>
      </li>
      <li>在 PyTorch 中保存：
        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="sh">'</span><span class="s">model.pth</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>输出中间层结果：</strong>
    <ul>
      <li>定义模型输出中间层的操作，例如获取 LSTM 输出状态。</li>
    </ul>
  </li>
</ol>

<hr />

<h3 id="5-怎么改进"><strong>5. 怎么改进？</strong></h3>
<h4 id="模型架构改进"><strong>模型架构改进：</strong></h4>
<ol>
  <li><strong>双向 LSTM (BiLSTM)：</strong>
提高捕获前后上下文信息的能力。
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Bidirectional</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Bidirectional</span><span class="p">(</span><span class="nc">LSTM</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">time_steps</span><span class="p">,</span> <span class="n">features</span><span class="p">)))</span>
</code></pre></div>    </div>
  </li>
  <li><strong>引入注意力机制 (Attention)：</strong>
增强模型对重要时间步的关注能力。
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Attention</span>
<span class="n">attention</span> <span class="o">=</span> <span class="nc">Attention</span><span class="p">()</span>  <span class="c1"># 需要具体实现
</span></code></pre></div>    </div>
  </li>
  <li><strong>混合模型：</strong>
    <ul>
      <li>使用 CNN 提取特征，结合 LSTM 时间序列建模。</li>
    </ul>
  </li>
</ol>

<h4 id="数据改进"><strong>数据改进：</strong></h4>
<ul>
  <li>数据增强：
    <ul>
      <li>对时间序列进行数据增强（滑动窗口、随机裁剪）。</li>
    </ul>
  </li>
  <li>特征工程：
    <ul>
      <li>提取更多时间序列特征（均值、方差、趋势等）。</li>
    </ul>
  </li>
</ul>

<h4 id="优化技巧"><strong>优化技巧：</strong></h4>
<ul>
  <li>使用预训练的嵌入层（如词向量）。</li>
  <li>增加模型训练轮数，结合学习率调度器逐步减少学习率。</li>
</ul>

<h4 id="对比模型"><strong>对比模型：</strong></h4>
<ul>
  <li>使用 GRU（门控循环单元），对比其性能。</li>
  <li>测试 Transformer 模型在时间序列数据中的表现。</li>
</ul>]]></content><author><name></name></author><category term="review" /><category term="diary" /><summary type="html"><![CDATA[LSTM 是一种广泛用于时间序列预测和序列数据建模的深度学习模型。]]></summary></entry><entry><title type="html">关于LSTM的模型建构(1)</title><link href="http://localhost:4000/review/diary/diary003/" rel="alternate" type="text/html" title="关于LSTM的模型建构(1)" /><published>2025-01-19T13:01:30+08:00</published><updated>2025-01-19T13:01:30+08:00</updated><id>http://localhost:4000/review/diary/diary003</id><content type="html" xml:base="http://localhost:4000/review/diary/diary003/"><![CDATA[<p>怎么建模?</p>

<p>怎么调整?</p>

<p>怎么调参?</p>

<p>怎么即时输出参数?</p>

<p>怎么改进?</p>]]></content><author><name></name></author><category term="review" /><category term="diary" /><summary type="html"><![CDATA[怎么建模?]]></summary></entry><entry><title type="html">对于人生的追求(2)</title><link href="http://localhost:4000/review/diary/diary002/" rel="alternate" type="text/html" title="对于人生的追求(2)" /><published>2025-01-18T13:01:30+08:00</published><updated>2025-01-18T13:01:30+08:00</updated><id>http://localhost:4000/review/diary/diary002</id><content type="html" xml:base="http://localhost:4000/review/diary/diary002/"><![CDATA[<p>退休应该要有的生活 应该是不后悔的生活模式 ，</p>

<p>带家人去旅行 带家人去吃美食 带家人等等的</p>

<p>也可以自己一个人享受一个人的旅行和生活</p>

<p>我财富自由后要一个人住，一个人生活，定时回家带家人去旅行。</p>

<p>这样就是我要的退休生活的生活模式</p>]]></content><author><name></name></author><category term="review" /><category term="diary" /><summary type="html"><![CDATA[退休应该要有的生活 应该是不后悔的生活模式 ，]]></summary></entry><entry><title type="html">forex 每日一句</title><link href="http://localhost:4000/forex/forex_words009/" rel="alternate" type="text/html" title="forex 每日一句" /><published>2025-01-18T11:01:30+08:00</published><updated>2025-01-18T11:01:30+08:00</updated><id>http://localhost:4000/forex/forex_words009</id><content type="html" xml:base="http://localhost:4000/forex/forex_words009/"><![CDATA[<p>Saturday｜18/365</p>

<p>The only way to achieve the impossible is to believe it is possible.</p>

<p>实现“不可能”唯一的方法，就是相信它是可能的。</p>]]></content><author><name></name></author><category term="forex" /><summary type="html"><![CDATA[Saturday｜18/365]]></summary></entry><entry><title type="html">对于人生的追求(1)</title><link href="http://localhost:4000/review/diary/diary001/" rel="alternate" type="text/html" title="对于人生的追求(1)" /><published>2025-01-17T13:01:30+08:00</published><updated>2025-01-17T13:01:30+08:00</updated><id>http://localhost:4000/review/diary/diary001</id><content type="html" xml:base="http://localhost:4000/review/diary/diary001/"><![CDATA[<p>我对于人生的追求很少欲望，只有简单的物欲和生活欲望就没有了</p>

<p>要购买医疗保险和好好存款做好退休的准备，</p>

<p>至于退休需要做什么，这需要好好想想。</p>

<p>旅游呢?</p>

<p>还是做自己想要的做的?</p>

<p>工作不是唯一的追求。</p>

<p>下一篇思考退休应该做什么?</p>]]></content><author><name></name></author><category term="review" /><category term="diary" /><summary type="html"><![CDATA[我对于人生的追求很少欲望，只有简单的物欲和生活欲望就没有了]]></summary></entry></feed>