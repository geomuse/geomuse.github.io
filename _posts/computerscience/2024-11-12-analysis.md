---
layout: post
title : data analysis
date : 2024-11-12 11:24:29 +0800
categories: 
    - stats
---

使用信用违约风险（Credit Default Risk）数据进行分析的过程通常包含以下关键步骤：
1. 数据收集与预处理

    数据来源：信用违约风险数据通常可以从银行、信用评级机构、金融机构等来源获取，也可以使用公开数据集如Kaggle的信用违约数据集。
    数据清洗：包括去除重复项、填充缺失值、去除异常值等。信用数据中的缺失值可能反映客户的财务状况或是数据采集过程中出现的问题。
    特征工程：将变量转化为合适的形式，比如将分类特征（如收入等级、婚姻状况）转化为数值编码或哑变量。

2. 探索性数据分析（EDA）

    单变量分析：检查各个变量的分布，如年龄、收入、贷款金额、信用评分等，特别关注信用违约率的分布。
    双变量分析：分析特征与违约情况的关系。比如，通过分析贷款金额、收入水平、信用评分等因素与违约之间的关联，可以发现违约风险的潜在影响因素。
    特征关联分析：使用相关性矩阵（如皮尔逊或斯皮尔曼相关系数）检查特征之间的关系，识别高度相关的特征，以减少多重共线性问题。

3. 特征选择

    相关性分析：使用相关性、卡方检验、F检验等方法，选择对违约风险有显著影响的特征。
    PCA（主成分分析）或因子分析：降低维度，减少特征的复杂性，帮助集中数据中的重要信息。
    Lasso回归：通过正则化选出对违约预测有影响的变量。

4. 模型构建

    逻辑回归：常用于信用违约预测的二分类问题，便于解释每个变量对违约的影响。
    决策树与随机森林：在捕获特征之间复杂关系方面效果较好，能够提供特征重要性，有助于理解影响违约的主要因素。
    梯度提升模型（如 XGBoost、LightGBM）：对复杂数据具有较好的预测效果，适用于多种非线性关系。
    神经网络：适用于大数据量的情况，能够捕捉非线性关系，但通常难以解释模型的输出。

5. 模型评估

    准确率、召回率、精确率和F1得分：用来衡量模型的表现，特别关注召回率，因为它能反映出违约风险的捕获情况。
    AUC-ROC曲线：评估分类器的性能，关注预测违约的能力。
    KS检验：在信用评分模型中使用较广，通过计算累计坏账率和累计好账率的最大差距，来衡量模型的区分能力。

6. 业务应用与解释

    违约概率：利用模型预测违约概率，帮助制定信用评分卡。
    信用评分卡：将违约概率转化为信用评分，便于在信贷审批时应用。
    变量重要性解释：通过SHAP值或LIME解释特征对违约风险的影响，帮助业务人员理解预测结果，提供针对性的信贷政策。

7. 风险管理与监控

    模型监控：确保模型在不同时间段的稳定性和准确性，避免因宏观经济变化或政策变化导致模型失效。
    调整策略：根据数据的动态更新信用政策和风控策略，以应对市场环境和客户行为的变化。

常用工具与技术
- 数据处理与分析：Python（pandas、numpy）、R
- 可视化：Matplotlib、Seaborn、Plotly
- 建模与评估：Scikit-learn、XGBoost、LightGBM

```py
# 导入必要的库
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
from sklearn.preprocessing import StandardScaler

# 加载数据
data = pd.read_csv('credit_default_risk.csv')

# 数据清洗
# 检查缺失值
data.isnull().sum()

# 填充缺失值（根据业务逻辑填充）
data['income'].fillna(data['income'].median(), inplace=True)

# 删除异常值（如收入过高或过低）
data = data[(data['income'] > 0) & (data['income'] < 500000)]

# 特征工程 - 将分类变量转化为数值变量（假设有些列是分类数据）
# data = pd.get_dummies(data, columns=['category_column'], drop_first=True)

# 数据标准化
scaler = StandardScaler()
data[['age', 'income', 'loan_amount', 'credit_score']] = scaler.fit_transform(data[['age', 'income', 'loan_amount', 'credit_score']])

# 数据分割
X = data[['age', 'income', 'loan_amount', 'credit_score']]
y = data['default']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 构建逻辑回归模型
log_model = LogisticRegression()
log_model.fit(X_train, y_train)

# 构建随机森林模型
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# 模型评估 - 逻辑回归
y_pred_log = log_model.predict(X_test)
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_log))
print("Classification Report:\n", classification_report(y_test, y_pred_log))

# 模型评估 - 随机森林
y_pred_rf = rf_model.predict(X_test)
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

# ROC曲线和AUC
y_prob_log = log_model.predict_proba(X_test)[:, 1]
y_prob_rf = rf_model.predict_proba(X_test)[:, 1]

fpr_log, tpr_log, _ = roc_curve(y_test, y_prob_log)
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)

plt.figure()
plt.plot(fpr_log, tpr_log, label='Logistic Regression (AUC = %0.2f)' % roc_auc_score(y_test, y_prob_log))
plt.plot(fpr_rf, tpr_rf, label='Random Forest (AUC = %0.2f)' % roc_auc_score(y_test, y_prob_rf))
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='best')
plt.show()

# 特征重要性（适用于随机森林）
feature_importances = pd.DataFrame(rf_model.feature_importances_, index=X.columns, columns=['importance']).sort_values('importance', ascending=False)
print("Feature Importances:\n", feature_importances)
```
