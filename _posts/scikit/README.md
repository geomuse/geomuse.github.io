## **Python机器学习 60天教学计划（Sklearn & Kaggle 数据分析）**

### **阶段 1：Python 基础复习与数据处理（Day 1-10）**

**目标**：确保掌握 Python 基础和数据处理能力。
**内容**：

1. **Day 1-2**：Python 基础复习

   * 变量、数据类型（int, float, str, list, dict, set, tuple）
   * 条件语句与循环
   * 函数与 lambda 表达式

2. **Day 3-4**：Numpy 入门

   * ndarray 创建、索引与切片
   * 数组运算、广播机制
   * 常用函数：sum, mean, std, reshape, concatenate

3. **Day 5-6**：Pandas 入门

   * Series 与 DataFrame 创建、索引、选择
   * 数据清洗：缺失值处理、重复值删除
   * 数据统计与描述：describe, value_counts

4. **Day 7-8**：数据可视化基础

   * Matplotlib：折线图、柱状图、散点图
   * Seaborn：heatmap, pairplot, boxplot

5. **Day 9-10**：Kaggle 数据下载与探索

   * 使用 Kaggle API 下载数据集
   * 查看数据结构、数据类型、缺失值、异常值
   * 初步可视化分析

---

### **阶段 2：数据预处理与特征工程（Day 11-25）**

**目标**：掌握机器学习建模前的数据清洗和特征处理。
**内容**：

1. **Day 11-13**：缺失值与异常值处理 ok 

   * 填充缺失值（均值、中位数、众数）
   * 异常值检测（箱线图、Z-score）

2. **Day 14-16**：类别特征处理

   * One-hot 编码、LabelEncoder
   * 分类特征处理注意事项（避免虚拟变量陷阱）

3. **Day 17-19**：数值特征处理

   * 标准化（StandardScaler）、归一化（MinMaxScaler）
   * 分箱（Binning）、多项式特征

4. **Day 20-22**：特征选择

   * 方差选择、相关性分析
   * 使用 sklearn 的 `SelectKBest`、`RFE` 方法

5. **Day 23-25**：处理时间序列和文本数据（可选）

   * 时间特征提取：年/月/日/星期
   * 文本特征：CountVectorizer、TF-IDF

---

### **阶段 3：监督学习建模（Day 26-40）**

**目标**：掌握常用监督学习算法与模型评估。
**内容**：

1. **Day 26-28**：线性模型

   * 线性回归（LinearRegression）
   * 岭回归（Ridge）、套索回归（Lasso）
   * 模型评估：MSE, RMSE, R²

2. **Day 29-31**：分类模型

   * 逻辑回归（LogisticRegression）
   * KNN（KNeighborsClassifier）
   * 决策树（DecisionTreeClassifier）
   * 模型评估：Accuracy, Precision, Recall, F1-score

3. **Day 32-34**：集成模型

   * 随机森林（RandomForestClassifier/Regressor）
   * XGBoost 简介与使用（可选）
   * 模型调参：GridSearchCV, RandomizedSearchCV

4. **Day 35-37**：支持向量机（SVM）

   * SVC / SVR
   * 核函数选择（linear, poly, rbf）

5. **Day 38-40**：模型评估与交叉验证

   * K-fold 交叉验证
   * 学习曲线（Learning Curve）、验证曲线（Validation Curve）
   * 混淆矩阵与 ROC 曲线

---

### **阶段 4：无监督学习与聚类（Day 41-50）**

**目标**：掌握无监督学习技术及特征降维。
**内容**：

1. **Day 41-43**：聚类分析

   * KMeans 聚类
   * 层次聚类（Hierarchical Clustering）
   * 聚类效果评估（轮廓系数）

2. **Day 44-46**：降维

   * PCA 主成分分析
   * 特征可视化与解释

3. **Day 47-50**：关联规则与异常检测

   * Apriori、FP-Growth
   * 异常检测：Isolation Forest, One-Class SVM

---

### **阶段 5：Kaggle 项目实战（Day 51-60）**

**目标**：综合运用所学技术完成 Kaggle 数据分析与模型提交。
**内容**：

1. **Day 51-52**：选择 Kaggle 竞赛与数据集

   * 常见竞赛类型：分类、回归、预测分析
   * 数据探索与问题理解

2. **Day 53-55**：特征工程与数据处理

   * 完整数据清洗流程
   * 特征选择与特征组合

3. **Day 56-57**：模型训练与调参

   * 选择合适模型（线性模型 / 决策树 / 集成模型）
   * 使用交叉验证与 GridSearchCV 调参

4. **Day 58-59**：模型融合（Ensemble）

   * 简单投票（Voting）
   * 堆叠（Stacking）
   * 提升模型性能

5. **Day 60**：提交 Kaggle

   * 生成提交文件
   * 评估模型表现
   * 总结经验，撰写分析报告

---

### **学习建议**

* 每天学习时间：1~2 小时理论 + 1 小时实战操作
* 所有练习都尽量用 Kaggle 公开数据集实战
* 关注 Sklearn 文档和 Kaggle Notebook 学习最佳实践


此30天学习计划旨在提供一个结构化的大纲，涵盖从基础机器学习概念到高级深度学习架构的实践应用，并严格遵循您要求的顺序：**数据分割 $\rightarrow$ 模型评估 $\rightarrow$ 模型优化 $\rightarrow$ 模型建立。**

此大纲基于核心算法和主流Python框架（如Scikit-Learn、Keras和TensorFlow）设计，以确保您在理论和实践上都能打下坚实的基础。

---

### 30天机器学习学习大纲

#### **第一阶段：基础概念、数据准备与优化基础 (第1天至第7天)**

此阶段集中建立机器学习项目的整体认知，掌握数据处理和评估模型的必要工具，这是所有模型构建（“模型建立”）的前提。

| 日期 | 主题 | 核心概念与实践内容 | 来源引用 |
| :--- | :--- | :--- | :--- |
| **第1天** | **机器学习与深度学习概述** | 机器学习定义、应用示例（垃圾邮件过滤、语音识别等）。理解有监督学习、无监督学习、强化学习、批量学习和在线学习等系统类型。机器学习项目流程：观察、获取数据、分析、训练、测试、启动。 |,,,,, |
| **第2天** | **数据分割（Segmentation）** | 确保训练数据的代表性（representativeness）是实现良好泛化的关键。了解采样偏差和数据窥探偏误。实践训练集、测试集和验证集的划分。对于非均匀数据（如收入），应用**分层抽样**确保代表性。 |,,,,,, |
| **第3天** | **模型评估（Evaluation） I** | **回归指标**：均方根误差（RMSE）和平均绝对误差（MAE）。**分类指标基础**：精度（Accuracy）为何不足以成为主要指标，以及混淆矩阵（Confusion Matrix）的重要性。 |,,,,, |
| **第4天** | **模型评估 II与分类核心** | 深入理解真负类/假正类（TN/FP）、精度（Precision）和召回率（Recall）的计算与权衡。学习F1分数。**ROC曲线与AUC**：AUC衡量分类器的平均性能。 |,,,,, |
| **第5天** | **模型优化（Optimization） I：梯度下降** | **成本函数**（如MSE）与参数空间。梯度下降（GD）核心思想：沿最陡方向调整参数。学习率（Learning Rate）的选择。批量梯度下降、随机梯度下降（SGD）和**小批量梯度下降**（Mini-batch GD）的差异。 |,,,,,,, |
| **第6天** | **模型优化 II：正则化与偏差/方差** | **偏差/方差权衡**。高方差（过拟合）与高偏差（欠拟合）。**正则化**（Regularization）：通过约束模型来减少过拟合。引入L2正则化（岭回归）和L1正则化（Lasso回归）的概念。 |,,,,, |
| **第7天** | **模型建立 I：线性基石** | **线性回归**（Standard Equation/SVD求解）和**逻辑回归**（Sigmoid函数与概率估计）。逻辑回归（Softmax）可以直接处理多类别分类。 |,,,,, |

#### **第二阶段：经典模型、正则化与高级优化 (第8天至第14天)**

此阶段开始集中于构建经典的机器学习模型，并将前一阶段的优化技术（如正则化）应用于这些模型。

| 日期 | 主题 | 核心概念与实践内容 | 来源引用 |
| :--- | :--- | :--- | :--- |
| **第8天** | **模型建立 II：K-近邻（kNN）** | kNN算法概述（基于实例的学习）、距离计算、超参数k的选择。理解特征缩放/归一化的必要性（防止大范围特征主导距离计算）。 |,,,,, |
| **第9天** | **模型建立 III：决策树** | CART算法：用于分类和回归任务，使用二元切分法。理解基尼不纯度或熵的概念。**剪枝**（Pruning）以避免过拟合：预剪枝与后剪枝。 |,,,,, |
| **第10天** | **模型建立 IV：支持向量机（SVM）** | 线性SVM：大间隔分类、**硬间隔与软间隔**。超参数C的调整。对异常值的敏感性。SVM相对于逻辑回归的优势（不输出概率）。 |,,,,, |
| **第11天** | **模型建立 V：核技巧与SVM回归** | **核技巧（Kernel Trick）**：隐式映射到高维空间解决非线性问题。常用的高斯RBF核。SVM回归：ε-不敏感，限制间隔违例。 |,,,,, |
| **第12天** | **模型优化 III：集成与高级优化器** | **集成方法**（Ensemble Methods）：投票分类器（硬投票/软投票），Bagging/Pasting（随机森林）。**提升法**（Boosting）：AdaBoost、梯度提升（针对残差拟合）。 |,,,,, |
| **第13天** | **模型建立 VI：无监督学习** | **K-均值聚类**：惯性（Inertia/SSE）度量，选择最佳k（肘部法则/轮廓分数）。**DBSCAN**：基于密度（而非中心点）的聚类，用于异常检测。 |,,,,, |
| **第14天** | **模型建立 VII：降维（PCA/kPCA）** | **维度的诅咒**。降维动机。PCA核心思想：最大化差异性。理解可解释方差比。核化PCA（kPCA）处理非线性流形。 |,,,,, |

#### **第三阶段：深度学习架构与训练技巧 (第15天至第21天)**

此阶段深入深度学习，重点学习MLP、CNN、RNN的架构、不稳定的梯度问题及其解决方案（模型优化的核心）。

| 日期 | 主题 | 核心概念与实践内容 | 来源引用 |
| :--- | :--- | :--- | :--- |
| **第15天** | **DNN训练 I：初始化与激活函数** | **梯度消失与梯度爆炸**问题。连接权重初始化：Glorot/He初始化。**非饱和激活函数**（如ReLU）取代S型函数。单元死亡问题与Leaky ReLU。 |,,,,, |
| **第16天** | **DNN训练 II：批量归一化（BN）** | **批量归一化**（Batch Normalization）：归一化层输入，解决梯度不稳定。BN在训练与测试时的行为差异。BN在模型中的位置（激活函数前/后）。 |,,,,, |
| **第17天** | **DNN训练 III：高级优化器** | **动量优化**（Momentum）和Nesterov加速梯度（NAG）。**自适应学习率优化器**：AdaGrad、RMSProp、Adam、Nadam（最常用）。 |,,,,, |
| **第18天** | **模型建立 VIII：卷积神经网络（CNN）** | **卷积层**：局部连接，接受野，权重共享。**池化层**：下采样，不变性（Invariance）。CNN的典型架构堆叠（Conv-ReLU-Pool）。 |,,,,, |
| **第19天** | **模型建立 IX：循环神经网络（RNN）** | **时间序列**数据处理。RNN结构：循环连接、随时间展开网络、隐藏状态（h）。SimpleRNN层与输出层。 |,,,,, |
| **第20天** | **模型建立 X：长期记忆单元** | **短期记忆问题**。**LSTM单元**（长期状态c和短期状态h，遗忘门/输入门/输出门）。**GRU单元**（LSTM的简化变体）。 |,,,,, |
| **第21天** | **模型建立 XI：自编码器（Autoencoders）** | 自动编码器：编码器（Encoder）和解码器（Decoder）。**不完整自动编码器**（降维）。堆叠式自编码器（特征提取）。二元交叉熵损失。 |,,,,, |

#### **第四阶段：深度架构、强化学习与部署 (第22天至第30天)**

此阶段转向生成模型、强化学习等前沿领域，并回归到项目最终目标：部署和大规模训练。

| 日期 | 主题 | 核心概念与实践内容 | 来源引用 |
| :--- | :--- | :--- | :--- |
| **第22天** | **模型建立 XII：变分自动编码器（VAE）** | **VAE**：生成式自动编码器，概率模型。编码（潜在表征）服从高斯分布。潜在损失和重构损失。 |,,,,, |
| **第23天** | **模型建立 XIII：生成式对抗网络（GANs）** | **GANs**：生成器与判别器的零和博弈（Zero-sum game）。对抗训练。DCGAN（深度卷积GAN）和StyleGAN概述。 |,,,,, |
| **第24天** | **CV高阶应用：物体检测与语义分割** | **目标定位**（Localization）：边界框回归。IoU指标。**语义分割**：像素级分类。FCN和U-Net架构。 |,,,,, |
| **第25天** | **CV高阶应用：迁移学习与预训练模型** | **迁移学习**（Transfer Learning）：重用预训练网络的低层，冻结/解冻/微调（Fine-tuning）权重。Keras应用中的预训练模型（如Xception）。 |,,,,, |
| **第26天** | **NLP高阶应用：情感分析与序列处理** | 词嵌入（Word Embeddings）。用RNN（LSTM/GRU）或CNN（WaveNet）处理长序列。文本分词与掩码（Masking）。 |,,,,, |
| **第27天** | **NLP高阶应用：Transformer与注意力机制** | **注意力机制**（Attention Mechanism）解决RNN短期记忆限制。**Transformer架构**：纯注意力机制模型，用于NMT。 |,,,,, |
| **第28天** | **模型建立 XIV：强化学习 I** | **强化学习基础**：智能体、策略、环境、回报。策略梯度（PG）算法：REINFORCE，优势（Advantage）计算。 |,,,,, |
| **第29天** | **模型建立 XV：深度Q学习** | **马尔可夫决策过程**（MDP）。Q-Learning，深度Q网络（DQN）。重播缓冲区（Replay Buffer）和ε-贪婪策略。 |,,,,, |
| **第30天** | **部署与大规模训练** | **模型部署**：SavedModel格式，TF Serving服务。**TFLite**（移动端部署和量化）。**大规模训练**：GPU加速、分布式策略（MirroredStrategy）。 |,,,,, |

第2天讲稿和代码