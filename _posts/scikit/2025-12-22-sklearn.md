---
layout: post
title:  pythonæœºå™¨å­¦ä¹  æ•°å€¼ç‰¹å¾å¤„ç†
date:   2025-12-22 09:01:00 +0800
image: 11.jpg
tags: 
    - python
    - sklearn
---

æ•°å€¼ç‰¹å¾ï¼ˆNumerical Featuresï¼‰æŒ‡ **å¯ä»¥è¿›è¡Œæ•°å­¦è¿ç®—çš„ç‰¹å¾**ï¼Œä¾‹å¦‚ï¼š

* å¹´é¾„ã€æ”¶å…¥ã€ä½™é¢
* äº¤æ˜“æ¬¡æ•°ã€é‡‘é¢
* è‚¡ä»·ã€æ”¶ç›Šç‡ã€æ³¢åŠ¨ç‡

æ•°å€¼ç‰¹å¾å¦‚æœ**ä¸å¤„ç†å¥½**ï¼Œä¼šç›´æ¥å¯¼è‡´ï¼š

* æ¢¯åº¦ä¸‹é™ä¸æ”¶æ•›
* æ¨¡å‹è¢«æŸäº›å¤§æ•°å€¼ç‰¹å¾â€œä¸»å¯¼â€
* éçº¿æ€§å…³ç³»æ— æ³•è¢«æ¨¡å‹æ•æ‰

---

## æ ‡å‡†åŒ–ï¼ˆStandardizationï¼‰

### StandardScalerï¼ˆZ-score æ ‡å‡†åŒ–ï¼‰

æŠŠæ•°æ®å˜æˆï¼š

* **å‡å€¼ = 0**
* **æ ‡å‡†å·® = 1**

å…¬å¼ï¼š
$$
x' = \frac{x - \mu}{\sigma}
$$

> æŠŠæ‰€æœ‰ç‰¹å¾â€œæ‹‰å›åŒä¸€ä¸ªå°ºåº¦â€ï¼Œæ¯”è¾ƒè°åç¦»å¹³å‡å€¼æ›´å¤š

#### Python ç¤ºä¾‹

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

* `fit` åªèƒ½åœ¨ **è®­ç»ƒé›†**
* æµ‹è¯•é›†åªèƒ½ `transform`

```python
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

---

## å½’ä¸€åŒ–ï¼ˆNormalizationï¼‰

### MinMaxScalerï¼ˆ0â€“1 ç¼©æ”¾ï¼‰

æŠŠæ•°æ®å‹ç¼©åˆ°ä¸€ä¸ªå›ºå®šåŒºé—´ï¼ˆé»˜è®¤ 0ï½1ï¼‰ï¼š

$$
x' = \frac{x - x_{min}}{x_{max} - x_{min}}
$$

> æŠŠæ‰€æœ‰ç‰¹å¾â€œæ‹‰è¿›åŒä¸€ä¸ªç›’å­é‡Œâ€

#### ğŸ“Œ Python 

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_norm = scaler.fit_transform(X)
```

---

## ä¸‰ã€StandardScaler vs MinMaxScaler å¯¹æ¯”

| å¯¹æ¯”é¡¹    | StandardScaler | MinMaxScaler |
| ------ | -------------- | ------------ |
| è¾“å‡ºèŒƒå›´   | æ— å›ºå®šèŒƒå›´          | 0ï½1          |
| æ˜¯å¦æŠ—å¼‚å¸¸å€¼ | âŒ å¦            | âŒ æ›´å·®         |
| æ˜¯å¦å¸¸ç”¨   | â­â­â­â­â­          | â­â­â­          |
| å¸¸è§ç”¨é€”   | çº¿æ€§æ¨¡å‹ / SVM     | NN / å›¾åƒ      |

ğŸ“Œ **ç»éªŒæ³•åˆ™**

> ä¸ç¡®å®šç”¨ä»€ä¹ˆ â†’ **StandardScaler**

---

## åˆ†ç®±ï¼ˆBinning / Discretizationï¼‰

### ä¸ºä»€ä¹ˆè¦åˆ†ç®±ï¼Ÿ

æ•°å€¼ç‰¹å¾æœ‰æ—¶ï¼š

* **éçº¿æ€§**
* **å¯¹æç«¯å€¼æ•æ„Ÿ**
* **é€»è¾‘ä¸Šæ›´åƒâ€œåŒºé—´â€**

ä¾‹å¦‚ï¼š

* å¹´é¾„ï¼š18â€“25 / 26â€“35 / 36â€“50
* æ”¶å…¥ï¼šä½ / ä¸­ / é«˜
* è¿çº¦é£é™©ï¼šä½™é¢åŒºé—´

---

### ç­‰å®½åˆ†ç®±ï¼ˆEqual Widthï¼‰

```python
import pandas as pd

df['age_bin'] = pd.cut(df['age'], bins=5)
```

* åŒºé—´å®½åº¦ç›¸ç­‰
* **æ ·æœ¬æ•°å¯èƒ½æä¸å‡è¡¡**

---

### ç­‰é¢‘åˆ†ç®±ï¼ˆQuantile Binningï¼‰

```python
df['age_bin'] = pd.qcut(df['age'], q=5)
```

* æ¯ä¸ªç®±å­æ ·æœ¬æ•°ç›¸è¿‘
* å¸¸ç”¨äº **ä¿¡ç”¨è¯„åˆ† / é£æ§**

---

### Sklearn åˆ†ç®±ï¼ˆæ¨èï¼‰

```python
from sklearn.preprocessing import KBinsDiscretizer

kbd = KBinsDiscretizer(
    n_bins=5,
    encode='onehot',
    strategy='quantile'
)

X_binned = kbd.fit_transform(X[['age']])
```

---

### åˆ†ç®±çš„ä¼˜ç¼ºç‚¹

#### ä¼˜ç‚¹

* é™ä½å¼‚å¸¸å€¼å½±å“
* æå‡æ¨¡å‹ç¨³å®šæ€§
* å¼ºåŒ–éçº¿æ€§è¡¨è¾¾

#### ç¼ºç‚¹

* ä¿¡æ¯æŸå¤±
* éœ€è¦è°ƒç®±æ•°

#### **å¸¸è§äº**

* é€»è¾‘å›å½’
* ä¿¡ç”¨è¯„åˆ†å¡
* è§„åˆ™æ¨¡å‹

---

## å¤šé¡¹å¼ç‰¹å¾ï¼ˆPolynomial Featuresï¼‰

### ä¸ºä»€ä¹ˆè¦å¤šé¡¹å¼ç‰¹å¾ï¼Ÿ

çº¿æ€§æ¨¡å‹æœ¬è´¨ï¼š
$$
y = w_1 x_1 + w_2 x_2
$$

ä½†ç°å®ä¸–ç•Œï¼š
$$
y = x^2,; x_1 \times x_2
$$

**å¤šé¡¹å¼ç‰¹å¾ = äººå·¥åˆ¶é€ éçº¿æ€§**

---

### ç¤ºä¾‹ï¼ˆ2 æ¬¡å¤šé¡¹å¼ï¼‰

```python
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(
    degree=2,
    include_bias=False
)

X_poly = poly.fit_transform(X)
```

å¦‚æœåŸæœ¬ï¼š

```
x1, x2
```

å˜æˆï¼š

```
x1, x2, x1Â², x1*x2, x2Â²
```

---

### ğŸ”Ÿ å¤šé¡¹å¼ç‰¹å¾çš„é£é™©

- ç‰¹å¾æ•°çˆ†ç‚¸
- å®¹æ˜“è¿‡æ‹Ÿåˆ
- è®¡ç®—æˆæœ¬é«˜

**æœ€ä½³å®è·µ**

* å…ˆæ ‡å‡†åŒ–
* degree â‰¤ 2 æˆ– 3
* æ­é…æ­£åˆ™åŒ–ï¼ˆL1 / L2ï¼‰

---

## å®Œæ•´æ¨èæµæ°´çº¿ï¼ˆPipelineï¼‰

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LogisticRegression

pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('poly', PolynomialFeatures(degree=2, include_bias=False)),
    ('model', LogisticRegression(penalty='l2'))
])

pipe.fit(X_train, y_train)
```