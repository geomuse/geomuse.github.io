---
layout: post
title:  pythonæœºå™¨å­¦ä¹  ç‰¹å¾é€‰æ‹©ï¼ˆFeature Selectionï¼‰
date:   2025-12-23 09:01:00 +0800
image: 11.jpg
tags: 
    - python
    - scikit
---

## ä¸ºä»€ä¹ˆè¦åšç‰¹å¾é€‰æ‹©ï¼Ÿ

åœ¨çœŸå®æ•°æ®ä¸­ï¼Œæˆ‘ä»¬å¸¸ä¼šé‡åˆ°ï¼š

* ç‰¹å¾å¤ªå¤šï¼ˆå‡ åã€ä¸Šç™¾ä¸ªï¼‰
* æœ‰äº›ç‰¹å¾**å‡ ä¹æ²¡å˜åŒ–**
* æœ‰äº›ç‰¹å¾**é«˜åº¦é‡å¤ï¼ˆé«˜åº¦ç›¸å…³ï¼‰**
* ç‰¹å¾å¤š â†’

  * æ¨¡å‹æ…¢
  * è¿‡æ‹Ÿåˆ
  * å¯è§£é‡Šæ€§å·®

> ç”¨ã€Œæ›´å°‘ã€æ›´æœ‰ç”¨ã€çš„ç‰¹å¾
> è¾¾åˆ°ã€Œæ›´å¥½æˆ–å·®ä¸å¤šã€çš„æ¨¡å‹æ•ˆæœ

---

## ç‰¹å¾é€‰æ‹©ä¸‰å¤§ç±»ï¼ˆå…ˆæœ‰æ¦‚å¿µï¼‰

ä»Šå¤©æˆ‘ä»¬é‡ç‚¹è®² **Filter & Wrapper**

| æ–¹æ³•       | æ€æƒ³       | æ˜¯å¦ç”¨æ¨¡å‹      |
| -------- | -------- | ---------- |
| Filter   | ç”¨ç»Ÿè®¡æ–¹æ³•ç­›ç‰¹å¾ | âŒ          |
| Wrapper  | ç”¨æ¨¡å‹åå¤è¯•   | âœ…          |
| Embedded | æ¨¡å‹è‡ªå·±é€‰    | âœ…ï¼ˆå¦‚ Lassoï¼‰ |

---

### ç›´è§‰ç†è§£

å¦‚æœä¸€ä¸ªç‰¹å¾ï¼š

* å‡ ä¹æ‰€æœ‰æ ·æœ¬éƒ½ä¸€æ ·
* é‚£å®ƒå¯¹ã€ŒåŒºåˆ†æ ·æœ¬ã€**æ²¡ä»€ä¹ˆå¸®åŠ©**

| ID | æ˜¯å¦VIP |
| -- | ----- |
| A  | 1     |
| B  | 1     |
| C  | 1     |

â†’ **æ²¡æœ‰åŒºåˆ†åº¦**

---

### sklearnï¼šVarianceThreshold

```python
from sklearn.feature_selection import VarianceThreshold

selector = VarianceThreshold(threshold=0.01)
X_new = selector.fit_transform(X)
```

* `threshold=0`ï¼šåªç§»é™¤**å®Œå…¨ä¸å˜**çš„ç‰¹å¾
* æ•°å€¼è¶Šå¤§ â†’ ç­›å¾—è¶Šä¸¥æ ¼

---

### ä»€ä¹ˆæ—¶å€™ç”¨ï¼Ÿ

- æ•°æ®åˆšæ•´ç†å®Œ
- ç‰¹å¾å¾ˆå¤š
- æƒ³**å¿«é€Ÿæ¸…æ‰åºŸç‰¹å¾**

> **ä¸çœ‹ yï¼ˆæ ‡ç­¾ï¼‰**ï¼Œåªæ˜¯çº¯ç»Ÿè®¡

---

## ç›¸å…³æ€§åˆ†æï¼ˆCorrelation Analysisï¼‰

### ä¸¤ç§å¸¸è§ç›¸å…³æ€§

#### ï¼ˆ1ï¼‰ç‰¹å¾ vs ç‰¹å¾ï¼ˆå»å†—ä½™ï¼‰

å¦‚æœä¸¤ä¸ªç‰¹å¾ï¼š

* ç›¸å…³ç³»æ•° â‰ˆ 0.95
* è¡¨è¾¾çš„æ˜¯å‡ ä¹åŒä¸€ä»¶äº‹

os: ç•™ä¸€ä¸ªå°±å¥½

```python
import pandas as pd

corr = X.corr()
```

---

#### ï¼ˆ2ï¼‰ç‰¹å¾ vs ç›®æ ‡ yï¼ˆé€‰é‡è¦ï¼‰

```python
corr_with_y = X.join(y).corr()['y'].sort_values(ascending=False)
```

| ç±»å‹    | æŒ‡æ ‡            |
| ----- | ------------- |
| è¿ç»­-è¿ç»­ | Pearson       |
| éçº¿æ€§   | Spearman      |
| åˆ†ç±»ç›®æ ‡  | ç‚¹äºŒåˆ—ç›¸å…³ / ANOVA |

---

### ç»éªŒæ³•åˆ™ï¼ˆæ•™å­¦ç”¨ï¼‰

* |corr| > 0.8ï¼šé«˜åº¦ç›¸å…³
* |corr| < 0.05ï¼šå‡ ä¹æ²¡ç”¨

os : ç›¸å…³ â‰  å› æœ
os : éçº¿æ€§æ¨¡å‹ï¼ˆæ ‘ã€NNï¼‰ç›¸å…³æ€§ä¸ä¸€å®šåæ˜ é‡è¦æ€§

---

## SelectKBestï¼ˆFilter æ–¹æ³•ï¼‰

> å¯¹æ¯ä¸ªç‰¹å¾ã€Œå•ç‹¬æ‰“åˆ†ã€
> é€‰åˆ†æ•°æœ€é«˜çš„ K ä¸ª

---

### å¸¸ç”¨æ‰“åˆ†å‡½æ•°

| å‡½æ•°              | é€‚ç”¨åœºæ™¯      |
| --------------- | --------- |
| `f_classif`     | åˆ†ç±»ï¼ˆANOVAï¼‰ |
| `chi2`          | åˆ†ç±»ï¼ˆéè´Ÿç‰¹å¾ï¼‰  |
| `f_regression`  | å›å½’        |
| `mutual_info_*` | éçº¿æ€§       |

---

### ç¤ºä¾‹ï¼ˆåˆ†ç±»ï¼‰

```python
from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(score_func=f_classif, k=5)
X_new = selector.fit_transform(X, y)
```

æŸ¥çœ‹å¾—åˆ†ï¼š

```python
selector.scores_
```

---

### ä¼˜ç¼ºç‚¹

âœ… å¿«
âœ… ç®€å•
âŒ ä¸è€ƒè™‘ç‰¹å¾ä¹‹é—´å…³ç³»

---

## RFEï¼ˆRecursive Feature Eliminationï¼‰

### æ€æƒ³ï¼ˆå¾ˆé‡è¦ï¼‰

> ç”¨æ¨¡å‹è®­ç»ƒ â†’
> åˆ æ‰æœ€ä¸é‡è¦çš„ç‰¹å¾ â†’
> å†è®­ç»ƒ â†’
> ç›´åˆ°å‰©ä¸‹ K ä¸ª

ğŸ“Œ **çœŸæ­£â€œç”¨æ¨¡å‹æ¥é€‰ç‰¹å¾â€**

---

### ç¤ºä¾‹ï¼ˆé€»è¾‘å›å½’ï¼‰

```python
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=1000)

rfe = RFE(
    estimator=model,
    n_features_to_select=5
)

X_new = rfe.fit_transform(X, y)
```

---

### 3ï¸âƒ£ æŸ¥çœ‹ç»“æœ

```python
rfe.support_   # True / False
rfe.ranking_   # æ’åï¼ˆ1 æ˜¯æœ€é‡è¦ï¼‰
```

---

### 4ï¸âƒ£ ä¼˜ç¼ºç‚¹

âœ… è€ƒè™‘ç‰¹å¾ç»„åˆ
âœ… æ¨¡å‹å¯¼å‘
âŒ è®¡ç®—æ…¢
âŒ ä¸é€‚åˆè¶…å¤§ç‰¹å¾æ•°

---

## ä»€ä¹ˆæ—¶å€™ç”¨å“ªä¸€ç§ï¼Ÿ

| åœºæ™¯          | æ¨è          |
| ----------- | ----------- |
| ç‰¹å¾å¾ˆå¤š        | æ–¹å·®ç­›é€‰ + ç›¸å…³æ€§  |
| å¿«é€Ÿ baseline | SelectKBest |
| ç‰¹å¾å°‘ä½†è¦æ±‚å‡†     | RFE         |
| æ ‘æ¨¡å‹         | å¸¸ç”¨å†…å»ºé‡è¦æ€§     |

---

## æ ‡å‡†æµç¨‹

```text
1ï¸âƒ£ æ•°æ®æ¸…æ´—
2ï¸âƒ£ æ–¹å·®ç­›é€‰
3ï¸âƒ£ ç›¸å…³æ€§å»å†—ä½™
4ï¸âƒ£ SelectKBest / RFE
5ï¸âƒ£ å»ºæ¨¡ + éªŒè¯
```
