---
layout: post
title:  python贪吃蛇游戏项目-自动化贪吃蛇理论
date:   2025-09-11 09:01:00 +0800
tags: 
    - python
    - game
image: 03.jpg
---

使用 规则驱动（Rule-based / Heuristic） 的方式

在学习强化学习（Reinforcement Learning, RL）之前，绝大多数初学者会直接跳进 DQN、PPO、A2C，结果往往是：

- 模型能跑，但不知道它在学什么
- Reward 一直震荡，完全无法 Debug
- 不知道「好策略」和「坏策略」差在哪里

因此，在教学与实务中，一个非常重要的步骤是：

先用“人类能理解的规则”，写出一个可运行、可解释的自动代理（Auto Agent）

这个 Agent 不需要聪明，但：

- 行为要可预测
- 逻辑要可解释

能当作强化学习的「Baseline（基线）」

这个函数的行为是在当前环境状态下，决定下一步要采取的动作（action）

短视但直接的策略

- 不考虑边界
- 容易进入死路
- 完全不考虑蛇身

```py
def auto_agent(self,env):
        """简单贪心策略：蛇头朝着食物走"""
        head_x, head_y = env.snake_x, env.snake_y
        food_x, food_y = env.food_x, env.food_y

        # 优先在 x 方向移动
        if food_x < head_x:
            return 2  # left
        elif food_x > head_x:
            return 3  # right
        elif food_y < head_y:
            return 0  # up
        elif food_y > head_y:
            return 1  # down
        else:
            return random.choice([0, 1, 2, 3])  # 如果重合就随机
```